{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import transforms as trans\n",
    "\n",
    "from data.ms1m import get_train_loader\n",
    "from data.lfw import LFW\n",
    "\n",
    "from backbone.arcfacenet import SEResNet_IR\n",
    "from margin.ArcMarginProduct import ArcMarginProduct \n",
    "from util.utils import save_checkpoint, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = edict()\n",
    "\n",
    "conf.train_root = './dataset/MS1M'\n",
    "conf.lfw_test_root = './dataset/lfw_aligned_112'\n",
    "conf.lfw_file_list = './dataset/lfw_pair.txt'\n",
    "\n",
    "conf.mode = 'se_ir' # 'ir'\n",
    "conf.depth = 50\n",
    "conf.margin_type = 'ArcFace'\n",
    "conf.feature_dim = 512\n",
    "conf.scale_size = 32.0\n",
    "conf.batch_size = 16 #16\n",
    "conf.lr = 0.01\n",
    "conf.milestones = [8, 10, 12]\n",
    "conf.total_epoch = 14\n",
    "\n",
    "conf.save_folder = './saved'\n",
    "conf.save_dir = os.path.join(conf.save_folder, conf.mode + '_' + str(conf.depth)) # ./saved/se_ir_50\n",
    "conf.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "conf.num_workers = 4\n",
    "conf.pin_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(conf.save_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = trans.Compose([\n",
    "    trans.ToTensor(), # range [0,255] -> [0.0, 1.0]\n",
    "    trans.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, class_num = get_train_loader(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of id: {class_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(trainloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfwdataset = LFW(conf.lfw_test_root, conf.lfw_file_list, transform = transform)\n",
    "lfwloader = torch.utils.data.DataLoader(lfwdataset, batch_size = 128, num_workers = conf.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SEResNet_IR(conf.depth, feature_dim = conf.feature_dim, mode = conf.mode).to(conf.device)\n",
    "margin = ArcMarginProduct(conf.feature_dim, class_num).to(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([\n",
    "    {'params' : net.parameters(),\n",
    "     'weight_decay' : 5e-4  \n",
    "    },\n",
    "    {'params' : margin.parameters(),\n",
    "     'weight_decay' : 5e-4  \n",
    "    }\n",
    "], lr = conf.lr, momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule_lr():\n",
    "    for params in optimizer.param_groups:\n",
    "        params['lr'] /= 10\n",
    "    print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "\n",
    "for epoch in range(1, conf.total_epoch+1):\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    #net.eval()\n",
    "    \n",
    "    print(f'epoch {epoch}/{conf.total_epoch}', flush = True)\n",
    "    \n",
    "    if epoch == conf.milestones[0]:\n",
    "        schedule_lr()\n",
    "    if epoch == conf.milestones[1]:\n",
    "        schedule_lr()\n",
    "    if epoch == conf.milestones[2]:\n",
    "        schedule_lr()\n",
    "        \n",
    "    for data in tqdm(trainloader):\n",
    "        img, label = data[0].to(conf.device), data[1].to(conf.device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = net(img)\n",
    "        output = margin(logits, label)\n",
    "        total_loss = criterion(output, label)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    #test\n",
    "    net.eval()\n",
    "    lfw_acc = test(conf, net, şfwdataset, lfwloader)\n",
    "    \n",
    "    print(f'\\nLFW : {lfw_acc} | train_loss : {total_loss.item()} \\n')\n",
    "    \n",
    "    is_best = lfw_acc > best_acc\n",
    "    best_acc = max(lfw_acc, best_acc)\n",
    "    \n",
    "    #saving model\n",
    "    save_checkpoint({\n",
    "        'epoch' : epoch,\n",
    "        'net_state_dict' : net.state_dict(),\n",
    "        'margin_state_dict' : margib.state_dict(),\n",
    "        'best_acc' : best_acc\n",
    "    }, is_best, checkpoint = conf.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SOTA : The state of the art\n",
    "\n",
    "1. MS1M datasetinin tamaminin indirilmesi ; alternatif olarak CASIA kullinilabilir; aşagidaki parametlere değiştirilebilir\n",
    "2. conf.mode = 'ir'\n",
    "3. conf.depth = '100'\n",
    "4. conf.total_epoch = 20\n",
    "5. conf.milestones = [12,16,18]\n",
    "\n",
    "lfw = 99.83%\n",
    "\n",
    "# 2 adet v100 (32 GB) -> 5 gün sürüyor\n",
    "\n",
    "Egitilen modeli cihaz üzerinde çalıştırmak (mobil yada kamera gibi) istenirse : MobileFaceNet arastirmasi yap\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
